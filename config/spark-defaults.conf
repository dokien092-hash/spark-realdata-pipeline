# Spark Configuration for Real Data Pipeline

# Driver Settings
spark.driver.memory                    2g
spark.driver.cores                     2
spark.driver.maxResultSize             1g

# Executor Settings
spark.executor.memory                  2g
spark.executor.cores                   2
spark.executor.instances               2

# Adaptive Query Execution
spark.sql.adaptive.enabled             true
spark.sql.adaptive.coalescePartitions.enabled  true
spark.sql.adaptive.coalescePartitions.minPartitionNum  1
spark.sql.adaptive.coalescePartitions.parallelismFirst  false
spark.sql.adaptive.skewJoin.enabled    true

# Streaming Settings
spark.streaming.kafka.maxRatePerPartition  1000
spark.streaming.backpressure.enabled   true
spark.streaming.receiver.maxRate       1000

# Shuffle Settings
spark.sql.shuffle.partitions           200
spark.shuffle.compress                 true
spark.shuffle.spill.compress           true

# Serialization
spark.serializer                       org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max        64m

# Memory Management
spark.sql.execution.arrow.pyspark.enabled  true
spark.sql.execution.arrow.maxRecordsPerBatch  10000

# Dynamic Allocation
spark.dynamicAllocation.enabled        false
spark.dynamicAllocation.minExecutors   1
spark.dynamicAllocation.maxExecutors   4

# Checkpointing and Recovery
spark.sql.streaming.checkpointLocation  /tmp/checkpoints
spark.sql.recovery.checkpointInterval   10s

# Delta Lake Configuration
spark.sql.extensions                   io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog        org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.databricks.delta.retentionDurationCheck.enabled  false
spark.databricks.delta.vacuum.parallelDelete.enabled   true

# Kafka Configuration
spark.kafka.bootstrap.servers          localhost:9092
spark.kafka.security.protocol          PLAINTEXT

# Monitoring and Metrics
spark.eventLog.enabled                 true
spark.eventLog.dir                     /tmp/spark-events
spark.history.fs.logDirectory          /tmp/spark-events
spark.metrics.conf.driver.sink.console.class  org.apache.spark.metrics.sink.ConsoleSink
spark.metrics.conf.executor.sink.console.class  org.apache.spark.metrics.sink.ConsoleSink

# Network and Storage
spark.network.timeout                  300s
spark.storage.memoryFraction           0.6
spark.storage.safetyFraction           0.9

# UI Configuration
spark.ui.port                          4040
spark.ui.retainedJobs                  1000
spark.ui.retainedStages                1000
