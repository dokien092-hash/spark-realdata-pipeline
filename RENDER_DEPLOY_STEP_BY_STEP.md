# ğŸ¨ HÆ°á»›ng dáº«n Deploy lÃªn Render.com - Tá»«ng bÆ°á»›c chi tiáº¿t

## ğŸ“‹ Tá»•ng quan

Render.com sáº½ host:
- **PostgreSQL** (free 90 ngÃ y â†’ $7/thÃ¡ng sau Ä‘Ã³)
- **Airflow Webserver** (Web Service - free, sáº½ sleep)
- **Airflow Scheduler** (Background Worker - free, KHÃ”NG sleep, cháº¡y 24/7)

## âœ… BÆ°á»›c 1: Chuáº©n bá»‹ code (5 phÃºt)

### 1.1. Push code lÃªn GitHub (náº¿u chÆ°a cÃ³)

```bash
cd /Users/kiendo/Downloads/Cole-mini-projects-develop/spark-mini-projects/spark-realdata-pipeline

# Kiá»ƒm tra git status
git status

# Náº¿u chÆ°a cÃ³ repo, init:
git init
git add .
git commit -m "Prepare for Render deployment"

# Táº¡o repo trÃªn GitHub vÃ  push:
# 1. VÃ o https://github.com/new
# 2. Táº¡o repo: spark-realdata-pipeline
# 3. Cháº¡y lá»‡nh:
git remote add origin https://github.com/your-username/spark-realdata-pipeline.git
git push -u origin main
```

### 1.2. Verify cÃ¡c file Ä‘Ã£ cÃ³:
- âœ… `Dockerfile.render.webserver`
- âœ… `Dockerfile.render.scheduler`
- âœ… `sql/init.sql`
- âœ… `airflow/dags/financial_pipeline_dag.py`
- âœ… `jobs/` folder

---

## âœ… BÆ°á»›c 2: Táº¡o PostgreSQL Database trÃªn Render (2 phÃºt)

### 2.1. ÄÄƒng kÃ½ Render
1. VÃ o https://render.com
2. Click **"Get Started for Free"**
3. ÄÄƒng kÃ½ báº±ng **GitHub account** (khuyáº¿n nghá»‹)

### 2.2. Táº¡o PostgreSQL Database
1. Dashboard â†’ Click **"+ New"** â†’ **"PostgreSQL"**
2. Äiá»n thÃ´ng tin:
   - **Name**: `realdata-postgres`
   - **Database**: `realdata_warehouse`
   - **User**: `postgres` (hoáº·c Ä‘á»ƒ Render tá»± táº¡o)
   - **Region**: **Singapore** (gáº§n VN nháº¥t)
   - **PostgreSQL Version**: `15`
   - **Plan**: **Free** (90 ngÃ y) hoáº·c **Starter** ($7/thÃ¡ng)
3. Click **"Create Database"**
4. âš ï¸ **QUAN TRá»ŒNG**: Copy **Internal Database URL**
   - Format: `postgresql://user:password@host:5432/dbname`
   - LÆ°u láº¡i, sáº½ cáº§n cho cÃ¡c bÆ°á»›c sau

### 2.3. Init Database Schema
1. TrÃªn **local machine** (Mac cá»§a báº¡n), cháº¡y:
```bash
cd /Users/kiendo/Downloads/Cole-mini-projects-develop/spark-mini-projects/spark-realdata-pipeline

# Set DATABASE_URL (paste Internal Database URL tá»« Render)
export DATABASE_URL="postgresql://user:pass@host:5432/dbname"

# Cháº¡y init script
bash scripts/init-render-db.sh
```

Hoáº·c manual:
```bash
# Install psql náº¿u chÆ°a cÃ³
brew install postgresql

# Connect vÃ  cháº¡y init.sql
psql "$DATABASE_URL" -f sql/init.sql
```

---

## âœ… BÆ°á»›c 3: Táº¡o Airflow Webserver (Web Service) (3 phÃºt)

### 3.1. Táº¡o Web Service
1. Render Dashboard â†’ **"+ New"** â†’ **"Web Service"**
2. **Connect** GitHub repo: `spark-realdata-pipeline`
3. Äiá»n thÃ´ng tin:
   - **Name**: `airflow-webserver`
   - **Region**: **Singapore**
   - **Branch**: `main`
   - **Runtime**: **Docker**
   - **Dockerfile Path**: `Dockerfile.render.webserver`
   - **Docker Context**: `.` (root)
   - **Plan**: **Free** (hoáº·c Starter $7/thÃ¡ng)
   - **Health Check Path**: `/health` (Airflow cÃ³ endpoint nÃ y)

### 3.2. Environment Variables
Click **"Advanced"** â†’ **"Environment Variables"**, thÃªm:

```bash
# Airflow Config
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=<paste Internal Database URL tá»« PostgreSQL>
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=false
AIRFLOW__CORE__LOAD_EXAMPLES=false
AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth

# API Keys
FINNHUB_API_KEY=d412e99r01qr2l0c96sgd412e99r01qr2l0c96t0
POLYGON_API_KEY=MKtaIeJgaIVQCxwr_HskC4NhLndLPZXR
ALPHA_VANTAGE_KEY=VWR51RQTVFTSBEL7
```

**LÆ°u Ã½**: Thay `<paste Internal Database URL>` báº±ng Internal Database URL tá»« PostgreSQL service.

### 3.3. Deploy
1. Click **"Create Web Service"**
2. Render sáº½ tá»± Ä‘á»™ng build vÃ  deploy
3. Äá»£i ~5-10 phÃºt Ä‘á»ƒ build xong
4. Láº¥y URL: `https://airflow-webserver.onrender.com`

### 3.4. Setup Airflow Admin User
Sau khi deploy xong, cáº§n táº¡o admin user. CÃ³ 2 cÃ¡ch:

**CÃ¡ch 1: DÃ¹ng Render Shell**
1. VÃ o webserver service â†’ **"Shell"** tab
2. Cháº¡y:
```bash
airflow users create \
  --role Admin \
  --username admin \
  --password admin \
  --email admin@example.com \
  --firstname admin \
  --lastname admin
```

**CÃ¡ch 2: ThÃªm vÃ o Dockerfile** (Ä‘Ã£ cÃ³ trong entrypoint cá»§a docker-compose, nhÆ°ng trÃªn Render cáº§n thÃªm)

---

## âœ… BÆ°á»›c 4: Táº¡o Airflow Scheduler (Background Worker) (3 phÃºt)

### 4.1. Táº¡o Background Worker
1. Render Dashboard â†’ **"+ New"** â†’ **"Background Worker"**
2. **Connect** cÃ¹ng GitHub repo: `spark-realdata-pipeline`
3. Äiá»n thÃ´ng tin:
   - **Name**: `airflow-scheduler`
   - **Region**: **Singapore**
   - **Branch**: `main`
   - **Runtime**: **Docker**
   - **Dockerfile Path**: `Dockerfile.render.scheduler`
   - **Docker Context**: `.` (root)
   - **Plan**: **Free** (Background Worker khÃ´ng sleep)

### 4.2. Environment Variables
**GIá»NG Há»†T** webserver:

```bash
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=<same Internal Database URL>
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=false
AIRFLOW__CORE__LOAD_EXAMPLES=false
FINNHUB_API_KEY=d412e99r01qr2l0c96sgd412e99r01qr2l0c96t0
POLYGON_API_KEY=MKtaIeJgaIVQCxwr_HskC4NhLndLPZXR
ALPHA_VANTAGE_KEY=VWR51RQTVFTSBEL7
```

### 4.3. Deploy
1. Click **"Create Background Worker"**
2. Äá»£i build xong (~5-10 phÃºt)

**LÆ°u Ã½**: Background Worker sáº½ cháº¡y **24/7**, khÃ´ng sleep nhÆ° Web Service.

---

## âœ… BÆ°á»›c 5: Setup Airflow Admin User

Sau khi cáº£ 2 services Ä‘Ã£ deploy xong:

1. VÃ o **airflow-webserver** service â†’ **"Shell"** tab
2. Cháº¡y:
```bash
airflow db init
airflow users create \
  --role Admin \
  --username admin \
  --password admin \
  --email admin@example.com \
  --firstname admin \
  --lastname admin
```

3. Restart webserver service (tá»« dashboard)

---

## âœ… BÆ°á»›c 6: Verify vÃ  Test

### 6.1. Access Airflow UI
1. Má»Ÿ URL: `https://airflow-webserver.onrender.com`
2. Login: `admin` / `admin`
3. Verify DAG `financial_pipeline_dag` Ä‘Ã£ xuáº¥t hiá»‡n

### 6.2. Unpause DAG
1. Trong Airflow UI â†’ **DAGs**
2. TÃ¬m `financial_pipeline_dag`
3. Toggle **OFF** (unpause)

### 6.3. Check Scheduler Logs
1. VÃ o **airflow-scheduler** service â†’ **"Logs"** tab
2. Xem logs Ä‘á»ƒ Ä‘áº£m báº£o scheduler Ä‘ang cháº¡y DAGs

### 6.4. Test Manual Trigger
1. Trong Airflow UI â†’ Click vÃ o DAG `financial_pipeline_dag`
2. Click **"Play"** button â†’ **"Trigger DAG"**
3. Xem logs Ä‘á»ƒ verify DAG cháº¡y OK

---

## ğŸ”§ Troubleshooting

### Webserver sleep sau 15 phÃºt
- **Normal behavior**: Free tier web service sáº½ sleep
- **Solution**: Scheduler (Background Worker) váº«n cháº¡y 24/7 vÃ  execute DAGs
- **Workaround**: DÃ¹ng cron job hoáº·c monitoring service Ä‘á»ƒ ping webserver má»—i 10 phÃºt

### Scheduler khÃ´ng cháº¡y DAGs
- Check logs cá»§a scheduler service
- Verify `AIRFLOW__DATABASE__SQL_ALCHEMY_CONN` Ä‘Ãºng
- Check DAG Ä‘Ã£ unpause chÆ°a

### Database connection failed
- Verify Internal Database URL Ä‘Ãºng format
- Check PostgreSQL service Ä‘Ã£ running
- Test connection tá»« local: `psql "$DATABASE_URL" -c "SELECT 1;"`

### DAG khÃ´ng xuáº¥t hiá»‡n
- Check logs cá»§a webserver vÃ  scheduler
- Verify `airflow/dags/` folder Ä‘Ã£ copy vÃ o Docker image
- Check DAG file syntax khÃ´ng cÃ³ lá»—i

---

## ğŸ’° Pricing Summary

**Free Tier:**
- âœ… PostgreSQL: Free 90 ngÃ y
- âœ… Web Service: Free (sleep sau 15 phÃºt)
- âœ… Background Worker: Free (khÃ´ng sleep, 24/7)

**After 90 days:**
- PostgreSQL: $7/thÃ¡ng (Starter plan)
- Web Service: Free (náº¿u dÃ¹ng free plan)
- Background Worker: Free

**Total: ~$7/thÃ¡ng sau 90 ngÃ y**

---

## ğŸ“š TÃ i liá»‡u tham kháº£o
- Render Docs: https://render.com/docs
- Docker on Render: https://render.com/docs/docker
- Airflow on Render: https://render.com/docs/airflow (community guides)

---

**âœ¨ HoÃ n táº¥t! Pipeline sáº½ tá»± Ä‘á»™ng cháº¡y lÃºc 7 AM VN (0:00 UTC) tá»« T2-T6**

