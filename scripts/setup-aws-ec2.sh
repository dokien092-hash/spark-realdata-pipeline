#!/bin/bash
# Script tá»± Ä‘á»™ng setup trÃªn AWS EC2
# Cháº¡y trÃªn EC2 sau khi SSH vÃ o

set -e

echo "ğŸš€ Báº¯t Ä‘áº§u setup tá»± Ä‘á»™ng trÃªn EC2..."
echo ""

# 1. VÃ o thÆ° má»¥c project
cd ~/spark-realdata-pipeline || exit 1

# 2. Táº¡o file .env vá»›i API keys tá»« docker-compose.yml defaults
echo "ğŸ“ Táº¡o file .env vá»›i API keys..."
cat > .env << 'EOF'
POLYGON_API_KEY=MKtaIeJgaIVQCxwr_HskC4NhLndLPZXR
ALPHA_VANTAGE_KEY=VWR51RQTVFTSBEL7
FINNHUB_API_KEY=d412e99r01qr2l0c96sgd412e99r01qr2l0c96t0
EOF

echo "âœ… ÄÃ£ táº¡o .env file"
echo ""

# 3. Set quyá»n cho scripts
echo "ğŸ” Set quyá»n cho scripts..."
chmod +x scripts/*.sh 2>/dev/null || true

# 4. Kiá»ƒm tra docker-compose
echo "ğŸ³ Kiá»ƒm tra Docker vÃ  Docker Compose..."
docker --version
docker-compose --version
echo ""

# 5. Cháº¡y Docker Compose
echo "ğŸš€ Khá»Ÿi Ä‘á»™ng Docker Compose..."
echo "   (Láº§n Ä‘áº§u sáº½ máº¥t 3-5 phÃºt Ä‘á»ƒ pull images)"
echo ""

docker-compose up -d

# 6. Chá» containers khá»Ÿi Ä‘á»™ng
echo "â³ Äá»£i containers khá»Ÿi Ä‘á»™ng (30 giÃ¢y)..."
sleep 30

# 7. Kiá»ƒm tra status
echo ""
echo "ğŸ“Š Kiá»ƒm tra status containers..."
docker-compose ps

# 8. Kiá»ƒm tra logs Airflow scheduler
echo ""
echo "ğŸ“‹ Logs Airflow Scheduler (20 dÃ²ng cuá»‘i):"
docker-compose logs airflow-scheduler --tail 20

# 9. Kiá»ƒm tra DAG
echo ""
echo "ğŸ” Kiá»ƒm tra DAG status..."
docker-compose exec -T airflow-webserver airflow dags list 2>/dev/null | grep financial_pipeline_dag || echo "   (Chá» thÃªm vÃ i giÃ¢y Ä‘á»ƒ Airflow init xong)"

echo ""
echo "âœ… Setup hoÃ n táº¥t!"
echo ""
echo "ğŸŒ Airflow UI: http://$(curl -s http://169.254.169.254/latest/meta-data/public-ipv4):8081"
echo "   Username: admin"
echo "   Password: admin"
echo ""
echo "ğŸ“ Lá»‡nh há»¯u Ã­ch:"
echo "   - Xem logs: docker-compose logs airflow-scheduler --tail 50"
echo "   - Check containers: docker-compose ps"
echo "   - Stop: docker-compose down"
echo "   - Restart: docker-compose restart"





