# ============================================================
# HƯỚNG DẪN CHẠY TỪNG LỆNH TRỰC TIẾP TRÊN EC2
# Copy từng lệnh và paste vào EC2 terminal
# ============================================================

# BƯỚC 1: SSH vào EC2 (chạy trên Mac terminal)
ssh -i ~/Downloads/financial-pipeline-key.pem ec2-user@3.25.91.76

# BƯỚC 2: Trên EC2 terminal, chạy từng lệnh sau:

# Lệnh 1: Di chuyển vào project
cd ~/spark-realdata-pipeline

# Lệnh 2: Tạo .env file
cat > .env << 'EOF'
POLYGON_API_KEY=MKtaIeJgaIVQCxwr_HskC4NhLndLPZXR
ALPHA_VANTAGE_KEY=VWR51RQTVFTSBEL7
FINNHUB_API_KEY=d412e99r01qr2l0c96sgd412e99r01qr2l0c96t0
EOF

# Lệnh 3: Khởi động containers
docker-compose down
docker-compose up -d

# Lệnh 4: Đợi và kiểm tra
sleep 30
docker-compose ps

# Lệnh 5: Init Airflow database
docker exec airflow-scheduler airflow db init

# Lệnh 6: Setup auto-start service
sudo tee /etc/systemd/system/docker-compose.service > /dev/null << 'EOF'
[Unit]
Description=Docker Compose Application Service
Requires=docker.service
After=docker.service

[Service]
Type=oneshot
RemainAfterExit=yes
WorkingDirectory=/home/ec2-user/spark-realdata-pipeline
ExecStart=/usr/local/bin/docker-compose up -d
ExecStop=/usr/local/bin/docker-compose down
User=ec2-user
Group=docker

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl daemon-reload
sudo systemctl enable docker-compose.service

# Lệnh 7: Kiểm tra auto-start
sudo systemctl is-enabled docker-compose.service

# Lệnh 8: Đợi Airflow ready
sleep 60

# Lệnh 9: Check và unpause DAG
docker-compose exec airflow-webserver airflow dags list | grep financial
docker-compose exec airflow-webserver airflow dags unpause financial_pipeline_dag

# Lệnh 10: Kiểm tra kết quả
docker-compose ps
echo "Airflow UI: http://$(curl -s http://169.254.169.254/latest/meta-data/public-ipv4):8081"




