#!/bin/bash

# Start Financial Data Pipeline
# Simplified script for financial data processing

set -e

echo "ğŸš€ Starting Financial Data Pipeline..."

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Docker is not running. Please start Docker first."
    exit 1
fi

# Start all services
echo "ğŸ“¦ Starting services..."
docker-compose up -d

# Wait for services to be ready
echo "â³ Waiting for services to be ready..."
sleep 30

# Check service health
echo "ğŸ” Checking service health..."
docker-compose ps

# Ensure Airflow DAG is unpaused
echo "ğŸ“… Ensuring Airflow DAG is unpaused..."
docker-compose exec airflow-webserver airflow dags unpause financial_pipeline_dag || true

# Optional backfill: set START_DATE=YYYY-MM-DD END_DATE=YYYY-MM-DD before running this script
if [ -n "$START_DATE" ] && [ -n "$END_DATE" ]; then
    echo "âª Backfilling data from $START_DATE to $END_DATE (inclusive)..."
    docker-compose exec airflow-webserver python /opt/airflow/jobs/data_processing/collect_monthly_data.py --start_date "$START_DATE" --end_date "$END_DATE"
else
    echo "ğŸ“¡ Starting daily scheduler-driven pipeline (no manual backfill requested)"
fi

echo ""
echo "âœ… Financial Data Pipeline Started!"
echo ""
echo "ğŸŒ Access Points:"
echo "  - Jupyter Lab: http://localhost:8888"
echo "  - Airflow: http://localhost:8081 (admin/admin)"
echo "  - Grafana: http://localhost:3000 (admin/admin)"
echo ""
echo "ğŸ“Š Pipeline Components:"
echo "  âœ… Data Ingestion (Yahoo Finance â†’ Kafka)"
echo "  âœ… Data Processing (Kafka â†’ PostgreSQL)"
echo "  âœ… Airflow DAG (Workflow orchestration)"
echo "  âœ… Grafana Dashboard (Monitoring)"
echo ""
echo "ğŸ” Check pipeline status:"
echo "  - Kafka topics: docker-compose exec kafka kafka-topics --list --bootstrap-server localhost:9092"
echo "  - PostgreSQL data: docker-compose exec postgres psql -U postgres -d realdata_warehouse -c 'SELECT COUNT(*) FROM stocks_daily;'"
echo "  - Airflow DAGs: curl -s http://localhost:8081/api/v1/dags"
echo ""
echo "ğŸ“‹ Next steps:"
echo "  1. Open Jupyter Lab to run financial analysis"
echo "  2. Check Grafana dashboard for monitoring"
echo "  3. Monitor Airflow DAG for workflow status"

