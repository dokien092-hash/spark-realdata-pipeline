#!/bin/bash
# Script cháº¡y TRÃŠN EC2 Ä‘á»ƒ kiá»ƒm tra tá»± Ä‘á»™ng cháº¡y lÃºc 7h sÃ¡ng

cd ~/spark-realdata-pipeline

echo "ğŸ” KIá»‚M TRA Tá»° Äá»˜NG CHáº Y LÃšC 7H SÃNG"
echo "=========================================="
echo ""

echo "âœ… 1. Kiá»ƒm tra Docker containers:"
echo "--------------------------------------------"
docker-compose ps
echo ""

echo "âœ… 2. Kiá»ƒm tra Auto-start service:"
echo "--------------------------------------------"
if sudo systemctl is-enabled docker-compose.service 2>/dev/null; then
    echo "âœ… Auto-start ENABLED"
    sudo systemctl status docker-compose.service --no-pager | head -8
else
    echo "âš ï¸  Auto-start NOT ENABLED"
    echo ""
    echo "ğŸ”§ Setup auto-start (copy vÃ  cháº¡y):"
    echo "sudo tee /etc/systemd/system/docker-compose.service > /dev/null << 'EOF'
[Unit]
Description=Docker Compose Application Service
Requires=docker.service
After=docker.service

[Service]
Type=oneshot
RemainAfterExit=yes
WorkingDirectory=/home/ec2-user/spark-realdata-pipeline
ExecStart=/usr/local/bin/docker-compose up -d
ExecStop=/usr/local/bin/docker-compose down
User=ec2-user
Group=docker

[Install]
WantedBy=multi-user.target
EOF
sudo systemctl daemon-reload
sudo systemctl enable docker-compose.service"
fi
echo ""

echo "âœ… 3. Kiá»ƒm tra Airflow DAG:"
echo "--------------------------------------------"
sleep 5
DAG_STATUS=$(docker-compose exec -T airflow-webserver airflow dags list 2>/dev/null | grep financial_pipeline_dag || echo "")
if [ -n "$DAG_STATUS" ]; then
    echo "âœ… DAG found:"
    echo "$DAG_STATUS"
    
    # Check schedule
    SCHEDULE_INFO=$(docker-compose exec -T airflow-webserver airflow dags show financial_pipeline_dag 2>/dev/null | grep -A 2 "schedule_interval" | head -3 || echo "")
    if [ -n "$SCHEDULE_INFO" ]; then
        echo ""
        echo "ğŸ“… Schedule info:"
        echo "$SCHEDULE_INFO"
    fi
else
    echo "âš ï¸  DAG chÆ°a load - Ä‘á»£i scheduler init (1-2 phÃºt)"
fi
echo ""

echo "âœ… 4. Kiá»ƒm tra Database:"
echo "--------------------------------------------"
if docker-compose exec -T postgres pg_isready -U postgres 2>/dev/null | grep -q "accepting"; then
    echo "âœ… PostgreSQL OK"
else
    echo "âš ï¸  PostgreSQL not ready"
fi
echo ""

echo "âœ… 5. Kiá»ƒm tra Scheduler logs (errors only):"
echo "--------------------------------------------"
docker-compose logs airflow-scheduler --tail 30 2>/dev/null | grep -i "error\|exception\|failed" | tail -5 || echo "âœ… No recent errors"
echo ""

echo "âœ… 6. Kiá»ƒm tra .env file:"
echo "--------------------------------------------"
if [ -f .env ]; then
    echo "âœ… .env exists"
    if grep -q "FINNHUB_API_KEY=" .env && ! grep -q "FINNHUB_API_KEY=$" .env; then
        echo "âœ… FINNHUB_API_KEY configured"
    else
        echo "âš ï¸  FINNHUB_API_KEY missing in .env"
    fi
else
    echo "âš ï¸  .env missing - create it with API keys"
fi
echo ""

echo "âœ… 7. Tá»•ng káº¿t:"
echo "--------------------------------------------"
PUBLIC_IP=$(curl -s http://169.254.169.254/latest/meta-data/public-ipv4 2>/dev/null || echo "N/A")
echo "ğŸŒ Airflow UI: http://${PUBLIC_IP}:8081"
echo "   Username: admin | Password: admin"
echo ""
echo "â° DAG sáº½ tá»± Ä‘á»™ng cháº¡y lÃºc 7:00 AM VN (0:00 UTC) tá»« T2-T6"
echo ""
echo "ğŸ“ Äá»ƒ Ä‘áº£m báº£o tá»± Ä‘á»™ng cháº¡y:"
echo "   1. âœ… Containers Ä‘ang cháº¡y"
echo "   2. âš ï¸  Auto-start service ENABLED (check trÃªn)"
echo "   3. âš ï¸  DAG schedule Ä‘Ãºng (check trÃªn)"
echo "   4. âš ï¸  DAG khÃ´ng bá»‹ PAUSED (check trong Airflow UI)"




